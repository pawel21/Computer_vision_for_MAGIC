{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69c3c3ce-d759-420b-b1b6-ed68013417df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from ipywidgets import interact, Dropdown, IntText\n",
    "\n",
    "import cv2\n",
    "from skimage import feature\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "from MirrorExtractor.mirror_extractor import MirrorExtractor\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36d4c7c5-9010-4d40-86a9-ed00781184f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MirrorFeatureExtractor:\n",
    "    \"\"\"Extracts features from mirror images\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_all_features(mirror_img):\n",
    "        \"\"\"\n",
    "        Extract all features from a single mirror image\n",
    "        \n",
    "        Args:\n",
    "            mirror_img: numpy array of shape (H, W, 3)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of feature name -> feature value\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Brightness features\n",
    "        features['brightness_mean'] = np.mean(mirror_img)\n",
    "        features['brightness_std'] = np.std(mirror_img)\n",
    "        features['brightness_min'] = np.min(mirror_img)\n",
    "        features['brightness_max'] = np.max(mirror_img)\n",
    "        \n",
    "        # Channel-specific features\n",
    "        for i, channel in enumerate(['R', 'G', 'B']):\n",
    "            features[f'{channel}_mean'] = np.mean(mirror_img[:, :, i])\n",
    "            features[f'{channel}_std'] = np.std(mirror_img[:, :, i])\n",
    "        \n",
    "        # Statistical features\n",
    "        features['skewness'] = skew(mirror_img.flatten())\n",
    "        features['kurtosis'] = kurtosis(mirror_img.flatten())\n",
    "        \n",
    "        # Texture features (if you want to add them later)\n",
    "        # gray = cv2.cvtColor(mirror_img, cv2.COLOR_RGB2GRAY)\n",
    "        # features['entropy'] = -np.sum(gray * np.log2(gray + 1e-10))\n",
    "        \n",
    "        return features\n",
    "\n",
    "class MirrorAnomalyDetector:\n",
    "    \"\"\"Detects anomalies in mirror images\"\"\"\n",
    "    \n",
    "    def __init__(self, extractor, feature_extractor=None, contamination=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            extractor: MirrorExtractor instance\n",
    "            feature_extractor: MirrorFeatureExtractor instance\n",
    "            contamination: Expected proportion of outliers (for IsolationForest)\n",
    "        \"\"\"\n",
    "        self.extractor = extractor\n",
    "        self.feature_extractor = feature_extractor or MirrorFeatureExtractor()\n",
    "        self.contamination = contamination\n",
    "        \n",
    "        # Storage for baseline models\n",
    "        self.baseline_stats = {}  # Statistical baseline (mean, std)\n",
    "        self.ml_models = {}       # ML models (IsolationForest)\n",
    "        self.scalers = {}         # Feature scalers\n",
    "        self.feature_names = None\n",
    "\n",
    "    def extract_mirror_from_image(self, img_path, mirror_id):\n",
    "        \"\"\"Extract a single mirror from an image\"\"\"\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        x_coords, y_coords = self.extractor.get_coords(mirror_id)\n",
    "        cropped = self.extractor.extract_polygon_region_cv2(img, x_coords, y_coords)\n",
    "        return cropped\n",
    "\n",
    "    def extract_features_from_images(self, img_path_list, mirror_id):\n",
    "        \"\"\"\n",
    "        Extract features from multiple images for a specific mirror\n",
    "        \n",
    "        Returns:\n",
    "            pandas DataFrame with features\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        for img_path in img_path_list:\n",
    "            mirror_img = self.extract_mirror_from_image(img_path, mirror_id)\n",
    "            features = self.feature_extractor.extract_all_features(mirror_img)\n",
    "            features_list.append(features)\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "        return df\n",
    "\n",
    "    def build_baseline(self, img_path_list, mirror_id_list):\n",
    "        \"\"\"\n",
    "        Build baseline models for multiple mirrors\n",
    "        \n",
    "        Args:\n",
    "            img_path_list: List of image paths for training\n",
    "            mirror_id_list: List of mirror IDs to create baselines for\n",
    "        \"\"\"\n",
    "        print(f\"Building baseline from {len(img_path_list)} images...\")\n",
    "        \n",
    "        for mirror_id in mirror_id_list:\n",
    "            print(f\"Processing mirror {mirror_id}...\")\n",
    "            \n",
    "            # Extract features\n",
    "            features_df = self.extract_features_from_images(img_path_list, mirror_id)\n",
    "            \n",
    "            if self.feature_names is None:\n",
    "                self.feature_names = features_df.columns.tolist()\n",
    "            \n",
    "            # Statistical baseline\n",
    "            self.baseline_stats[mirror_id] = {\n",
    "                'mean': features_df.mean().to_dict(),\n",
    "                'std': features_df.std().to_dict(),\n",
    "                'min': features_df.min().to_dict(),\n",
    "                'max': features_df.max().to_dict(),\n",
    "                'percentile_95': features_df.quantile(0.95).to_dict(),\n",
    "                'percentile_5': features_df.quantile(0.05).to_dict(),\n",
    "            }\n",
    "            \n",
    "            # ML-based baseline (Isolation Forest)\n",
    "            scaler = StandardScaler()\n",
    "            features_scaled = scaler.fit_transform(features_df)\n",
    "            \n",
    "            iso_forest = IsolationForest(\n",
    "                contamination=self.contamination,\n",
    "                random_state=42,\n",
    "                n_estimators=100\n",
    "            )\n",
    "            iso_forest.fit(features_scaled)\n",
    "            \n",
    "            self.scalers[mirror_id] = scaler\n",
    "            self.ml_models[mirror_id] = iso_forest\n",
    "            \n",
    "        print(\"Baseline building complete!\")\n",
    "\n",
    "    def detect_anomaly_statistical(self, features, mirror_id, n_std=3):\n",
    "        \"\"\"\n",
    "        Detect anomaly using statistical method (mean Â± n*std)\n",
    "        \n",
    "        Returns:\n",
    "            dict: Anomaly results\n",
    "        \"\"\"\n",
    "        baseline = self.baseline_stats[mirror_id]\n",
    "        anomalies = {}\n",
    "        \n",
    "        for feature_name, value in features.items():\n",
    "            mean = baseline['mean'][feature_name]\n",
    "            std = baseline['std'][feature_name]\n",
    "            \n",
    "            # Check if value is outside n standard deviations\n",
    "            lower_bound = mean - n_std * std\n",
    "            upper_bound = mean + n_std * std\n",
    "            \n",
    "            is_anomaly = value < lower_bound or value > upper_bound\n",
    "            \n",
    "            anomalies[feature_name] = {\n",
    "                'value': value,\n",
    "                'mean': mean,\n",
    "                'std': std,\n",
    "                'is_anomaly': is_anomaly,\n",
    "                'z_score': (value - mean) / (std + 1e-10),\n",
    "                'lower_bound': lower_bound,\n",
    "                'upper_bound': upper_bound\n",
    "            }\n",
    "        \n",
    "        # Overall anomaly decision\n",
    "        num_anomalies = sum(1 for v in anomalies.values() if v['is_anomaly'])\n",
    "        is_overall_anomaly = num_anomalies > 0\n",
    "        \n",
    "        return {\n",
    "            'is_anomaly': is_overall_anomaly,\n",
    "            'num_anomalous_features': num_anomalies,\n",
    "            'total_features': len(features),\n",
    "            'feature_details': anomalies\n",
    "        }\n",
    "\n",
    "    def detect_anomaly_with_stats(self, img_path, mirror_id, n_std=3):\n",
    "        \"\"\"\n",
    "        Detect anomaly in a new image\n",
    "        \n",
    "        Args:\n",
    "            img_path: Path to the image\n",
    "            mirror_id: Mirror ID to check\n",
    "            method: 'statistical', 'ml', or 'both'\n",
    "            n_std: Number of standard deviations for statistical method\n",
    "            \n",
    "        Returns:\n",
    "            dict: Complete anomaly detection results\n",
    "        \"\"\"\n",
    "        # Extract mirror and features\n",
    "        mirror_img = self.extract_mirror_from_image(img_path, mirror_id)\n",
    "        features = self.feature_extractor.extract_all_features(mirror_img)\n",
    "        \n",
    "        results = {\n",
    "            'mirror_id': mirror_id,\n",
    "            'image_path': img_path,\n",
    "            'features': features\n",
    "        }\n",
    "        \n",
    "        # Statistical detection\n",
    "        results['statistical'] = self.detect_anomaly_statistical(\n",
    "                features, mirror_id, n_std\n",
    "            )\n",
    "        return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43fa85-40c2-491b-ad45-db15cc1c12bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d218d7f-397a-436d-829e-ad066d0b3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 380 training images\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "extractor = MirrorExtractor(\n",
    "    \"/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/crossings_points.pkl\"\n",
    ")\n",
    "detector = MirrorAnomalyDetector(extractor, contamination=0.05)\n",
    "    \n",
    "# Get training images\n",
    "img_list = glob.glob(\n",
    "    \"/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/*.jpg\"\n",
    ")\n",
    "print(f\"Found {len(img_list)} training images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a202e343-c291-4cb5-b4de-a2e260724543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building baseline from 100 images...\n",
      "Processing mirror 15...\n",
      "Processing mirror 50...\n",
      "Processing mirror 100...\n",
      "Baseline building complete!\n"
     ]
    }
   ],
   "source": [
    "# Define mirrors to monitor\n",
    "mirror_id_list = [15, 50, 100]\n",
    "    \n",
    "# Build baseline (use subset for faster testing)\n",
    "detector.build_baseline(img_list[:100], mirror_id_list)  # Use more images in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2721bdb2-2af3-4815-bb8d-3ef1c273075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on new image\n",
    "new_image_path = '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg'\n",
    "    \n",
    "for mirror_id in mirror_id_list:\n",
    "    results = detector.detect_anomaly_with_stats(\n",
    "        new_image_path, \n",
    "        mirror_id, \n",
    "        n_std=2  # Adjust sensitivity (lower = more sensitive)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4096e337-d869-4f7f-b4e1-4c3b9ed7b5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 50, 100]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirror_id_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd6bc5ac-a160-4625-acd8-6ab3690b9d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mirror_id': 100,\n",
       " 'image_path': '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg',\n",
       " 'features': {'brightness_mean': np.float64(73.15789473684211),\n",
       "  'brightness_std': np.float64(55.26387438721731),\n",
       "  'brightness_min': np.uint8(0),\n",
       "  'brightness_max': np.uint8(255),\n",
       "  'R_mean': np.float64(73.70588235294117),\n",
       "  'R_std': np.float64(55.85748835783436),\n",
       "  'G_mean': np.float64(74.14551083591331),\n",
       "  'G_std': np.float64(55.26105120387236),\n",
       "  'B_mean': np.float64(71.62229102167183),\n",
       "  'B_std': np.float64(54.63342288653721),\n",
       "  'skewness': np.float64(0.40821644369227406),\n",
       "  'kurtosis': np.float64(0.3541626466324401)},\n",
       " 'statistical': {'is_anomaly': False,\n",
       "  'num_anomalous_features': 0,\n",
       "  'total_features': 12,\n",
       "  'feature_details': {'brightness_mean': {'value': np.float64(73.15789473684211),\n",
       "    'mean': 77.8688338493292,\n",
       "    'std': 15.36782103753858,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(-0.30654567755240986),\n",
       "    'lower_bound': 47.13319177425205,\n",
       "    'upper_bound': 108.60447592440636},\n",
       "   'brightness_std': {'value': np.float64(55.26387438721731),\n",
       "    'mean': 57.38667729364559,\n",
       "    'std': 10.807415159311839,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(-0.19642096422839841),\n",
       "    'lower_bound': 35.771846975021916,\n",
       "    'upper_bound': 79.00150761226926},\n",
       "   'brightness_min': {'value': np.uint8(0),\n",
       "    'mean': 0.0,\n",
       "    'std': 0.0,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(0.0),\n",
       "    'lower_bound': 0.0,\n",
       "    'upper_bound': 0.0},\n",
       "   'brightness_max': {'value': np.uint8(255),\n",
       "    'mean': 240.68,\n",
       "    'std': 27.625153228698853,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(0.5183681654685479),\n",
       "    'lower_bound': 185.4296935426023,\n",
       "    'upper_bound': 295.9303064573977},\n",
       "   'R_mean': {'value': np.float64(73.70588235294117),\n",
       "    'mean': 84.22455108359134,\n",
       "    'std': 18.01035019065854,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(-0.5840346589178204),\n",
       "    'lower_bound': 48.20385070227426,\n",
       "    'upper_bound': 120.24525146490842},\n",
       "   'R_std': {'value': np.float64(55.85748835783436),\n",
       "    'mean': 60.48197423449659,\n",
       "    'std': 12.199097652957382,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(-0.37908425755598585),\n",
       "    'lower_bound': 36.08377892858182,\n",
       "    'upper_bound': 84.88016954041136},\n",
       "   'G_mean': {'value': np.float64(74.14551083591331),\n",
       "    'mean': 79.5607120743034,\n",
       "    'std': 16.175116151343357,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(-0.33478592596733026),\n",
       "    'lower_bound': 47.21047977161668,\n",
       "    'upper_bound': 111.9109443769901},\n",
       "   'G_std': {'value': np.float64(55.26105120387236),\n",
       "    'mean': 57.30536210190469,\n",
       "    'std': 10.779470718397944,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(-0.18964854132626574),\n",
       "    'lower_bound': 35.7464206651088,\n",
       "    'upper_bound': 78.86430353870058},\n",
       "   'B_mean': {'value': np.float64(71.62229102167183),\n",
       "    'mean': 69.82123839009289,\n",
       "    'std': 13.970480395907432,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(0.1289184466479518),\n",
       "    'lower_bound': 41.88027759827803,\n",
       "    'upper_bound': 97.76219918190775},\n",
       "   'B_std': {'value': np.float64(54.63342288653721),\n",
       "    'mean': 52.528613214626766,\n",
       "    'std': 9.15791718520377,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(0.22983497549946758),\n",
       "    'lower_bound': 34.21277884421923,\n",
       "    'upper_bound': 70.8444475850343},\n",
       "   'skewness': {'value': np.float64(0.40821644369227406),\n",
       "    'mean': 0.09630019222945208,\n",
       "    'std': 0.4650003933291646,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(0.6707870700120976),\n",
       "    'lower_bound': -0.8337005944288771,\n",
       "    'upper_bound': 1.0263009788877813},\n",
       "   'kurtosis': {'value': np.float64(0.3541626466324401),\n",
       "    'mean': -0.2925070741274381,\n",
       "    'std': 0.9012623130396247,\n",
       "    'is_anomaly': np.False_,\n",
       "    'z_score': np.float64(0.717515546064662),\n",
       "    'lower_bound': -2.0950317002066874,\n",
       "    'upper_bound': 1.5100175519518113}}}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66640c00-06a1-4570-807e-35eeee48b3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e66be-7841-4b93-bb26-58729c3f57c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d6c26-d6ec-4de9-a751-1dd3eb05785c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dfb71-9d1c-4d12-bb4e-6f1d54c12ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62097b5-d354-4837-a726-edd84289caf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60993be9-3e63-45f5-b582-3fd2a4eb31fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9973c7-7525-470d-89c7-c1971a8e27bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b7962-454f-414e-ae57-919d87ec3b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172ae5d-8c26-4fa8-92a4-f37c31910244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa1c8a6c-0851-432c-94a3-4faf4e261d31",
   "metadata": {},
   "source": [
    "# My solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610dab1c-6aea-4e87-93e8-966586ce4112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_path, mirror_id):\n",
    "    img = Image.open(image_path)\n",
    "    x_coords, y_coords = extractor.get_coords(mirror_id)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(x_coords, y_coords, 'r-', lw=2)\n",
    "    plt.scatter(x_coords[:-1], y_coords[:-1], c='cyan', s=30)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    text_title = image_path.split('/')[-1] + \"mirror id:\" + str(mirror_id)\n",
    "    plt.title(text_title)\n",
    "    plt.show()\n",
    "\n",
    "def extract_one_mirror_from_images(img_path_list, mirror_id, extractor):\n",
    "    mirror_list = []\n",
    "    for path in img_path_list:\n",
    "        img = np.array(Image.open(path).convert('RGB'))\n",
    "        x_coords, y_coords = extractor.get_coords(mirror_id)\n",
    "        cropped = extractor.extract_polygon_region_cv2(img, x_coords, y_coords)\n",
    "        mirror_list.append(cropped)\n",
    "    return mirror_list\n",
    "\n",
    "def get_one_mirror_features(mirror_img):\n",
    "    brightness = np.mean(mirror)\n",
    "    brightness_std = np.std(mirror)\n",
    "    return brightness\n",
    "    \n",
    "def compute_mirror_features(mirror_list):\n",
    "    \"\"\"\n",
    "    Oblicza cechy dla kaÅ¼dego lustra\n",
    "    \"\"\"\n",
    "    features_dict = {}\n",
    "    brightness_list = []\n",
    "    brightness_std_list = []\n",
    "    \n",
    "    \n",
    "    for mirror in mirror_list:\n",
    "        brightness_list.append(np.mean(mirror))\n",
    "        brightness_std_list.append(np.std(mirror))\n",
    "    \n",
    "    features_dict[\"brightness\"] = brightness_list\n",
    "    features_dict[\"brightness_std\"] = brightness_std_list\n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7fae4a-fcce-4970-927c-83d0d194e437",
   "metadata": {},
   "source": [
    "## 1. Build base model with good images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5442b5-ca32-4440-a75d-1a141559ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = MirrorExtractor(\"/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/crossings_points.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38eaa3d8-478a-4d45-a9f0-3d38ddce4fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg', '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2023-01-04_1600.jpg', '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-07_1600.jpg', '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-04_1000.jpg', '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-21_1700.jpg']\n"
     ]
    }
   ],
   "source": [
    "img_list = glob.glob(\"/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/*.jpg\")\n",
    "print(img_list[:5])\n",
    "mirror_list_150 = extract_one_mirror_from_images(img_list[:], 150, extractor)\n",
    "mirror_list_50 = extract_one_mirror_from_images(img_list[:], 50, extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d7492f-9b90-41cd-bd08-338e4a4d500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_150 = compute_mirror_features(mirror_list_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "251e65fa-ac46-4c86-b774-0fac943dca62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['brightness', 'brightness_std'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_150.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e8539d7-ce84-48de-9f8f-f9d6aef18a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "50\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "mirror_id_list = [15, 50, 100]\n",
    "mirror_feature_list = []\n",
    "mirror_base_model_dict = {}\n",
    "\n",
    "for mirror_id in mirror_id_list:\n",
    "    print(mirror_id)\n",
    "    mirrors_list = extract_one_mirror_from_images(img_list[:], mirror_id, extractor)\n",
    "    feature_mirror = compute_mirror_features(mirrors_list)\n",
    "    mirror_feature_list.append(feature_mirror)\n",
    "    mirror_base_model_dict[f'id_{mirror_id}'] = {'mean_brightness':np.mean(feature_mirror[\"brightness\"]), \n",
    "                                                 'mean_std_brightness':np.mean(feature_mirror[\"brightness_std\"])}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "115da5fa-6bfa-4842-b137-ea81d6b61897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id_15': {'mean_brightness': np.float64(119.14611713106295),\n",
       "  'mean_std_brightness': np.float64(84.39408997511109)},\n",
       " 'id_50': {'mean_brightness': np.float64(116.54099136730717),\n",
       "  'mean_std_brightness': np.float64(87.22786908682455)},\n",
       " 'id_100': {'mean_brightness': np.float64(77.49262940633318),\n",
       "  'mean_std_brightness': np.float64(56.84909484092278)}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirror_base_model_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f086c-c8d3-4140-9e6a-92f8478740ab",
   "metadata": {},
   "source": [
    "# Test on new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f64b0ac-82dd-42af-9bba-43be84686cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Annomarly\n",
      "50\n",
      "Annomarly\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "new_image_path = '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg'\n",
    "mirror_id_list = [15, 50, 100]\n",
    "new_img_list = [new_image_path]\n",
    "for mirror_id in mirror_id_list:\n",
    "    print(mirror_id)\n",
    "    mirror = extract_one_mirror_from_images(new_img_list[:], mirror_id, extractor)\n",
    "    brightness = np.mean(mirror)\n",
    "    brightness_std = np.std(mirror)\n",
    "    if brightness > mirror_base_model_dict[f\"id_{mirror_id}\"][\"mean_brightness\"]:\n",
    "        print(\"Annomarly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ab0e60-dc3d-4b56-9076-7eb55f94eee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror_status = np.ones(289)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955e11c-dd80-4ab4-b483-066027bff08a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
