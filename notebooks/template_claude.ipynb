{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1711f3c7-8419-41d8-a2c5-2082fc02b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image as IPImage\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, Dropdown, IntText\n",
    "import cv2\n",
    "from skimage import feature\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from MirrorExtractor.mirror_extractor import MirrorExtractor\n",
    "\n",
    "\n",
    "class MirrorFeatureExtractor:\n",
    "    \"\"\"Extracts features from mirror images\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_all_features(mirror_img):\n",
    "        \"\"\"\n",
    "        Extract all features from a single mirror image\n",
    "        \n",
    "        Args:\n",
    "            mirror_img: numpy array of shape (H, W, 3)\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of feature name -> feature value\n",
    "        \"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Brightness features\n",
    "        features['brightness_mean'] = np.mean(mirror_img)\n",
    "        features['brightness_std'] = np.std(mirror_img)\n",
    "        features['brightness_min'] = np.min(mirror_img)\n",
    "        features['brightness_max'] = np.max(mirror_img)\n",
    "        \n",
    "        # Channel-specific features\n",
    "        for i, channel in enumerate(['R', 'G', 'B']):\n",
    "            features[f'{channel}_mean'] = np.mean(mirror_img[:, :, i])\n",
    "            features[f'{channel}_std'] = np.std(mirror_img[:, :, i])\n",
    "        \n",
    "        # Statistical features\n",
    "        features['skewness'] = skew(mirror_img.flatten())\n",
    "        features['kurtosis'] = kurtosis(mirror_img.flatten())\n",
    "        \n",
    "        # Texture features (if you want to add them later)\n",
    "        # gray = cv2.cvtColor(mirror_img, cv2.COLOR_RGB2GRAY)\n",
    "        # features['entropy'] = -np.sum(gray * np.log2(gray + 1e-10))\n",
    "        \n",
    "        return features\n",
    "\n",
    "\n",
    "class MirrorAnomalyDetector:\n",
    "    \"\"\"Detects anomalies in mirror images\"\"\"\n",
    "    \n",
    "    def __init__(self, extractor, feature_extractor=None, contamination=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            extractor: MirrorExtractor instance\n",
    "            feature_extractor: MirrorFeatureExtractor instance\n",
    "            contamination: Expected proportion of outliers (for IsolationForest)\n",
    "        \"\"\"\n",
    "        self.extractor = extractor\n",
    "        self.feature_extractor = feature_extractor or MirrorFeatureExtractor()\n",
    "        self.contamination = contamination\n",
    "        \n",
    "        # Storage for baseline models\n",
    "        self.baseline_stats = {}  # Statistical baseline (mean, std)\n",
    "        self.ml_models = {}       # ML models (IsolationForest)\n",
    "        self.scalers = {}         # Feature scalers\n",
    "        self.feature_names = None\n",
    "        \n",
    "    def extract_mirror_from_image(self, img_path, mirror_id):\n",
    "        \"\"\"Extract a single mirror from an image\"\"\"\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        x_coords, y_coords = self.extractor.get_coords(mirror_id)\n",
    "        cropped = self.extractor.extract_polygon_region_cv2(img, x_coords, y_coords)\n",
    "        return cropped\n",
    "    \n",
    "    def extract_features_from_images(self, img_path_list, mirror_id):\n",
    "        \"\"\"\n",
    "        Extract features from multiple images for a specific mirror\n",
    "        \n",
    "        Returns:\n",
    "            pandas DataFrame with features\n",
    "        \"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        for img_path in img_path_list:\n",
    "            mirror_img = self.extract_mirror_from_image(img_path, mirror_id)\n",
    "            features = self.feature_extractor.extract_all_features(mirror_img)\n",
    "            features_list.append(features)\n",
    "        \n",
    "        df = pd.DataFrame(features_list)\n",
    "        return df\n",
    "    \n",
    "    def build_baseline(self, img_path_list, mirror_id_list):\n",
    "        \"\"\"\n",
    "        Build baseline models for multiple mirrors\n",
    "        \n",
    "        Args:\n",
    "            img_path_list: List of image paths for training\n",
    "            mirror_id_list: List of mirror IDs to create baselines for\n",
    "        \"\"\"\n",
    "        print(f\"Building baseline from {len(img_path_list)} images...\")\n",
    "        \n",
    "        for mirror_id in mirror_id_list:\n",
    "            print(f\"Processing mirror {mirror_id}...\")\n",
    "            \n",
    "            # Extract features\n",
    "            features_df = self.extract_features_from_images(img_path_list, mirror_id)\n",
    "            \n",
    "            if self.feature_names is None:\n",
    "                self.feature_names = features_df.columns.tolist()\n",
    "            \n",
    "            # Statistical baseline\n",
    "            self.baseline_stats[mirror_id] = {\n",
    "                'mean': features_df.mean().to_dict(),\n",
    "                'std': features_df.std().to_dict(),\n",
    "                'min': features_df.min().to_dict(),\n",
    "                'max': features_df.max().to_dict(),\n",
    "                'percentile_95': features_df.quantile(0.95).to_dict(),\n",
    "                'percentile_5': features_df.quantile(0.05).to_dict(),\n",
    "            }\n",
    "            \n",
    "            # ML-based baseline (Isolation Forest)\n",
    "            scaler = StandardScaler()\n",
    "            features_scaled = scaler.fit_transform(features_df)\n",
    "            \n",
    "            iso_forest = IsolationForest(\n",
    "                contamination=self.contamination,\n",
    "                random_state=42,\n",
    "                n_estimators=100\n",
    "            )\n",
    "            iso_forest.fit(features_scaled)\n",
    "            \n",
    "            self.scalers[mirror_id] = scaler\n",
    "            self.ml_models[mirror_id] = iso_forest\n",
    "            \n",
    "        print(\"Baseline building complete!\")\n",
    "    \n",
    "    def detect_anomaly_statistical(self, features, mirror_id, n_std=3):\n",
    "        \"\"\"\n",
    "        Detect anomaly using statistical method (mean Â± n*std)\n",
    "        \n",
    "        Returns:\n",
    "            dict: Anomaly results\n",
    "        \"\"\"\n",
    "        baseline = self.baseline_stats[mirror_id]\n",
    "        anomalies = {}\n",
    "        \n",
    "        for feature_name, value in features.items():\n",
    "            mean = baseline['mean'][feature_name]\n",
    "            std = baseline['std'][feature_name]\n",
    "            \n",
    "            # Check if value is outside n standard deviations\n",
    "            lower_bound = mean - n_std * std\n",
    "            upper_bound = mean + n_std * std\n",
    "            \n",
    "            is_anomaly = value < lower_bound or value > upper_bound\n",
    "            \n",
    "            anomalies[feature_name] = {\n",
    "                'value': value,\n",
    "                'mean': mean,\n",
    "                'std': std,\n",
    "                'is_anomaly': is_anomaly,\n",
    "                'z_score': (value - mean) / (std + 1e-10),\n",
    "                'lower_bound': lower_bound,\n",
    "                'upper_bound': upper_bound\n",
    "            }\n",
    "        \n",
    "        # Overall anomaly decision\n",
    "        num_anomalies = sum(1 for v in anomalies.values() if v['is_anomaly'])\n",
    "        is_overall_anomaly = num_anomalies > 0\n",
    "        \n",
    "        return {\n",
    "            'is_anomaly': is_overall_anomaly,\n",
    "            'num_anomalous_features': num_anomalies,\n",
    "            'total_features': len(features),\n",
    "            'feature_details': anomalies\n",
    "        }\n",
    "    \n",
    "    def detect_anomaly_ml(self, features, mirror_id):\n",
    "        \"\"\"\n",
    "        Detect anomaly using ML method (Isolation Forest)\n",
    "        \n",
    "        Returns:\n",
    "            dict: Anomaly results\n",
    "        \"\"\"\n",
    "        # Convert features to DataFrame\n",
    "        features_df = pd.DataFrame([features])\n",
    "        \n",
    "        # Scale features\n",
    "        features_scaled = self.scalers[mirror_id].transform(features_df)\n",
    "        \n",
    "        # Predict\n",
    "        prediction = self.ml_models[mirror_id].predict(features_scaled)[0]\n",
    "        anomaly_score = self.ml_models[mirror_id].score_samples(features_scaled)[0]\n",
    "        \n",
    "        is_anomaly = prediction == -1\n",
    "        \n",
    "        return {\n",
    "            'is_anomaly': is_anomaly,\n",
    "            'anomaly_score': anomaly_score,\n",
    "            'prediction': prediction\n",
    "        }\n",
    "    \n",
    "    def detect_anomaly(self, img_path, mirror_id, method='both', n_std=3):\n",
    "        \"\"\"\n",
    "        Detect anomaly in a new image\n",
    "        \n",
    "        Args:\n",
    "            img_path: Path to the image\n",
    "            mirror_id: Mirror ID to check\n",
    "            method: 'statistical', 'ml', or 'both'\n",
    "            n_std: Number of standard deviations for statistical method\n",
    "            \n",
    "        Returns:\n",
    "            dict: Complete anomaly detection results\n",
    "        \"\"\"\n",
    "        # Extract mirror and features\n",
    "        mirror_img = self.extract_mirror_from_image(img_path, mirror_id)\n",
    "        features = self.feature_extractor.extract_all_features(mirror_img)\n",
    "        \n",
    "        results = {\n",
    "            'mirror_id': mirror_id,\n",
    "            'image_path': img_path,\n",
    "            'features': features\n",
    "        }\n",
    "        \n",
    "        # Statistical detection\n",
    "        if method in ['statistical', 'both']:\n",
    "            results['statistical'] = self.detect_anomaly_statistical(\n",
    "                features, mirror_id, n_std\n",
    "            )\n",
    "        \n",
    "        # ML detection\n",
    "        if method in ['ml', 'both']:\n",
    "            results['ml'] = self.detect_anomaly_ml(features, mirror_id)\n",
    "        \n",
    "        # Combined decision\n",
    "        if method == 'both':\n",
    "            results['is_anomaly'] = (\n",
    "                results['statistical']['is_anomaly'] or \n",
    "                results['ml']['is_anomaly']\n",
    "            )\n",
    "        elif method == 'statistical':\n",
    "            results['is_anomaly'] = results['statistical']['is_anomaly']\n",
    "        else:\n",
    "            results['is_anomaly'] = results['ml']['is_anomaly']\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_anomaly_report(self, results):\n",
    "        \"\"\"Print a formatted anomaly detection report\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ANOMALY DETECTION REPORT\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Mirror ID: {results['mirror_id']}\")\n",
    "        print(f\"Image: {results['image_path']}\")\n",
    "        print(f\"\\nOVERALL RESULT: {'â ï¸ ANOMALY DETECTED' if results['is_anomaly'] else 'â NORMAL'}\")\n",
    "        \n",
    "        if 'statistical' in results:\n",
    "            stat = results['statistical']\n",
    "            print(f\"\\n--- Statistical Method ---\")\n",
    "            print(f\"Anomalous features: {stat['num_anomalous_features']}/{stat['total_features']}\")\n",
    "            \n",
    "            # Show top anomalies\n",
    "            anomalous_features = [\n",
    "                (name, details) \n",
    "                for name, details in stat['feature_details'].items() \n",
    "                if details['is_anomaly']\n",
    "            ]\n",
    "            \n",
    "            if anomalous_features:\n",
    "                print(\"\\nTop anomalous features:\")\n",
    "                for name, details in sorted(anomalous_features, \n",
    "                                           key=lambda x: abs(x[1]['z_score']), \n",
    "                                           reverse=True)[:5]:\n",
    "                    print(f\"  - {name}: {details['value']:.2f} \"\n",
    "                          f\"(expected: {details['mean']:.2f} Â± {details['std']:.2f}, \"\n",
    "                          f\"z-score: {details['z_score']:.2f})\")\n",
    "        \n",
    "        if 'ml' in results:\n",
    "            ml = results['ml']\n",
    "            print(f\"\\n--- ML Method (Isolation Forest) ---\")\n",
    "            print(f\"Prediction: {'ANOMALY' if ml['is_anomaly'] else 'NORMAL'}\")\n",
    "            print(f\"Anomaly score: {ml['anomaly_score']:.4f}\")\n",
    "        \n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    # Initialize\n",
    "    extractor = MirrorExtractor(\n",
    "        \"/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/crossings_points.pkl\"\n",
    "    )\n",
    "    detector = MirrorAnomalyDetector(extractor, contamination=0.05)\n",
    "    \n",
    "    # Get training images\n",
    "    img_list = glob.glob(\n",
    "        \"/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/*.jpg\"\n",
    "    )\n",
    "    print(f\"Found {len(img_list)} training images\")\n",
    "    \n",
    "    # Define mirrors to monitor\n",
    "    mirror_id_list = [15, 50, 100]\n",
    "    \n",
    "    # Build baseline (use subset for faster testing)\n",
    "    detector.build_baseline(img_list[:100], mirror_id_list)  # Use more images in production\n",
    "    \n",
    "    # Test on new image\n",
    "    new_image_path = '/home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg'\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TESTING ANOMALY DETECTION ON NEW IMAGE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for mirror_id in mirror_id_list:\n",
    "        results = detector.detect_anomaly(\n",
    "            new_image_path, \n",
    "            mirror_id, \n",
    "            method='both',\n",
    "            n_std=2  # Adjust sensitivity (lower = more sensitive)\n",
    "        )\n",
    "        detector.print_anomaly_report(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e14e39d-f544-4ba6-93ee-e48f6599dd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 380 training images\n",
      "Building baseline from 100 images...\n",
      "Processing mirror 15...\n",
      "Processing mirror 50...\n",
      "Processing mirror 100...\n",
      "Baseline building complete!\n",
      "\n",
      "============================================================\n",
      "TESTING ANOMALY DETECTION ON NEW IMAGE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ANOMALY DETECTION REPORT\n",
      "============================================================\n",
      "Mirror ID: 15\n",
      "Image: /home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg\n",
      "\n",
      "OVERALL RESULT: â NORMAL\n",
      "\n",
      "--- Statistical Method ---\n",
      "Anomalous features: 0/12\n",
      "\n",
      "--- ML Method (Isolation Forest) ---\n",
      "Prediction: NORMAL\n",
      "Anomaly score: -0.4788\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANOMALY DETECTION REPORT\n",
      "============================================================\n",
      "Mirror ID: 50\n",
      "Image: /home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg\n",
      "\n",
      "OVERALL RESULT: â NORMAL\n",
      "\n",
      "--- Statistical Method ---\n",
      "Anomalous features: 0/12\n",
      "\n",
      "--- ML Method (Isolation Forest) ---\n",
      "Prediction: NORMAL\n",
      "Anomaly score: -0.4645\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "ANOMALY DETECTION REPORT\n",
      "============================================================\n",
      "Mirror ID: 100\n",
      "Image: /home/pgliwny/Praca/Computer_vision_for_MAGIC/data/webcam_useful_image/webcam_useful_images/image_2024-05-09_1500.jpg\n",
      "\n",
      "OVERALL RESULT: â NORMAL\n",
      "\n",
      "--- Statistical Method ---\n",
      "Anomalous features: 0/12\n",
      "\n",
      "--- ML Method (Isolation Forest) ---\n",
      "Prediction: NORMAL\n",
      "Anomaly score: -0.4140\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c655e-7a03-4dd0-b62f-96e00fa8c102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
